{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6ae600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a82cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading all: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73ec8b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01aa462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781bcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "121c84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1fb41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | paint\n",
      "walking | walk\n",
      "dressing | dress\n",
      "likely | like\n",
      "children | children\n",
      "whom | whom\n",
      "good | good\n",
      "ate | ate\n",
      "fishing | fish\n"
     ]
    }
   ],
   "source": [
    "for word in lst_words:\n",
    "    print(f\"{word} | {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2580f36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f813a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running | run\n",
      "painting | paint\n",
      "walking | walk\n",
      "dressing | dress\n",
      "likely | likely\n",
      "children | child\n",
      "who | who\n",
      "good | good\n",
      "ate | eat\n",
      "fishing | fishing\n"
     ]
    }
   ],
   "source": [
    "for text in doc:\n",
    "    lemma = text.lemma_\n",
    "    print(f\"{text} | {lemma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3045f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5510806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_word = nltk.word_tokenize(text)\n",
    "token_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4c419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "up2_txt = []\n",
    "for token in token_word:\n",
    "    stm = stemmer.stem(token)\n",
    "    up2_txt.append(stm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3 = ''\n",
    "for txt in up2_txt:\n",
    "    txt3 += ''.join(txt)+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03325b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9946a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = nlp(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2936c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemma_str = ''\n",
    "for txt2 in model2:\n",
    "    lemma = txt2.lemma_\n",
    "    lemma_str += ''.join(lemma)+' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cc6fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_str=lemma_str.replace(\"\\n\",\"\")\n",
    "\n",
    "lemma_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800d4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
